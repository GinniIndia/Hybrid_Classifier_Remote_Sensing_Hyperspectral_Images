# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dbbIAdN3W1d952w0GZkGEPGJ5f04Dq8k

Reading Data file and Normalization
"""

import scipy.io
import numpy as np
import numpy
from random import shuffle
import random
import scipy.ndimage
from skimage.transform import rotate
import os

DATA_PATH = os.path.join(os.getcwd())
input_mat = scipy.io.loadmat(os.path.join(DATA_PATH, 'Salinas_corrected.mat'))['salinas_corrected']
target_mat = scipy.io.loadmat(os.path.join(DATA_PATH, 'Salinas_gt.mat'))['salinas_gt']
#target_mat = scipy.io.loadmat(os.path.join(DATA_PATH, 'output_data.mat'))['output_data']

input_mat = input_mat.astype(float)
input_mat -= np.min(input_mat)
input_mat /= np.max(input_mat)

#print(input_mat.shape[1])

#count=0;
input_data1 = []; output_data1=[];
for i in range(input_mat.shape[0]):
  for j in range(input_mat.shape[1]):
    if(target_mat[i][j]!=0):
      input_data1.append(input_mat[i][j][:]);
      output_data1.append(target_mat[i][j]);
        #count=count+1;

scipy.io.savemat('output_data1.mat', {'output_data1':output_data1}, appendmat=True, format='5', long_field_names=False, do_compression=False, oned_as='row');   
scipy.io.savemat('input_data1.mat', {'input_data1':input_data1}, appendmat=True, format='5', long_field_names=False, do_compression=False, oned_as='row');   

input_data1 = np.array(input_data1);
output_data1 = np.array(output_data1);

output_datann = numpy.zeros(shape=(output_data1.shape[0], 16));
count = 0;
for i in output_data1:
  output_datann[count][i-1] = 1;
  count=count+1;

"""Multi-Layer Perceptron"""

# first neural network with keras tutorial
from keras.models import Sequential
from sklearn import metrics
from keras.layers import Dense
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import numpy
# load the dataset
#dataset = loadtxt('pima-indians-diabetes.csv', delimiter=',')
# split into input (X) and output (y) variables
X = input_data1;
y = output_datann;
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)
# define the keras model
model1 = Sequential()
model1.add(Dense(500, input_dim=204, activation='relu'))
model1.add(Dense(350, activation='relu'))
model1.add(Dense(250, activation='relu'))
model1.add(Dense(16, activation='softmax'))
# compile the keras model
model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
# fit the keras model on the dataset
#history = model.fit(X, y, epochs=5, batch_size=10)
history = model1.fit(X_train, y_train, epochs=500, batch_size=100, verbose=0)
# evaluate the keras model

_, accuracy = model1.evaluate(X_test, y_test)
print('Accuracy: %.2f' % (accuracy*100))

print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history['acc'])
#plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('acc')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
#plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

y_test1 = numpy.zeros(shape=(y_test.shape[0], 1))
for i in range(y_test.shape[0]):
  for j in range(y_test.shape[1]):
    if(y_test[i][j]==1):
      y_test1[i][0] = j+1;

# value stores predicted values of classed on bases of score and y_test1 stores actual classes.

y_pred1 = model1.predict(X_test);
value = numpy.zeros(shape=(y_pred1.shape[0], 1))
for i in range(y_pred1.shape[0]):
  idx = -1;
  for j in range(y_pred1.shape[1]):
    if(idx < y_pred1[i][j]):
      value[i][0] = j+1;
      idx =  y_pred1[i][j];

print(confusion_matrix(y_test1,value))
print(classification_report(y_test1,value))
print("Accuracy:",metrics.accuracy_score(y_test1, value))

"""Extraction of Weights"""

weights = [layer.get_weights() for layer in model1.layers]
weights = numpy.array(weights);
print(type(weights))
len(weights[0][0][3])
res = np.dot(input_data1,weights[0][0]);
res = np.maximum(res,0);
res = np.dot(res,weights[1][0]);
res = np.maximum(res,0);
res = np.dot(res,weights[2][0]);
res = np.maximum(res,0);

"""SVM"""

from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn import metrics
X_train, X_test, y_train, y_test = train_test_split(res, output_data1, test_size = 0.20)

from sklearn.model_selection import GridSearchCV 
param_grid = {'C': [100],  
              'gamma': [.01], 
              'kernel': ['rbf']}  
  
grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) 
grid.fit(X_train, y_train) 

#svclassifier = SVC(kernel='rbf')
#svclassifier.fit(X_train, y_train)
y_pred1 = grid.predict(X_test)
print(confusion_matrix(y_test,y_pred1))
print(classification_report(y_test,y_pred1))
print("Accuracy:",metrics.accuracy_score(y_test, y_pred1))

"""KNN"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn import metrics
X_train, X_test, y_train, y_test = train_test_split(res, output_data1, test_size = 0.20)
model2 = KNeighborsClassifier(n_neighbors=3)

# Train the model using the training sets
model2.fit(X_train,y_train)

#Predict Output
y_pred1= model2.predict(X_test) # 0:Overcast, 2:Mild
print(confusion_matrix(y_test,y_pred1))
print(classification_report(y_test,y_pred1))
print("Accuracy:",metrics.accuracy_score(y_test, y_pred1))

"""Decision Tree"""

import pandas as pd
from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier
from sklearn.model_selection import train_test_split # Import train_test_split function
from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation
from sklearn.metrics import classification_report, confusion_matrix

X_train, X_test, y_train, y_test = train_test_split(res, output_data1, test_size = 0.20)
# Create Decision Tree classifer object
clf = DecisionTreeClassifier()

# Train Decision Tree Classifer
clf = clf.fit(X_train,y_train)

#Predict the response for test dataset
y_pred1 = clf.predict(X_test)
print(confusion_matrix(y_test,y_pred1))
print(classification_report(y_test,y_pred1))
print("Accuracy:",metrics.accuracy_score(y_test, y_pred1))

"""Random Forest"""

from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn import metrics
X_train, X_test, y_train, y_test = train_test_split(res, output_data1, test_size = 0.20)
#Create a Gaussian Classifier
clf=RandomForestClassifier(n_estimators=51, oob_score=True)

#Train the model using the training sets y_pred=clf.predict(X_test)
clf.fit(X_train,y_train)

y_pred1=clf.predict(X_test)
print(confusion_matrix(y_test,y_pred1))
print(classification_report(y_test,y_pred1))
print("Accuracy:",metrics.accuracy_score(y_test, y_pred1))

"""Install Spectral Library"""

pip install spectral

"""Spectal Library for the representation of Prediction"""

input_datas = [];
for i in range(input_mat.shape[0]):
  for j in range(input_mat.shape[1]):
    #if(target_mat[i][j]!=0):
    input_datas.append(input_mat[i][j][:]);
      #output_data1.append(target_mat[i][j]);
        #count=count+1;

weights = numpy.array(weights);
print(type(weights))
len(weights[0][0][3])
res = np.dot(input_datas,weights[0][0]);
res = np.maximum(res,0);
res = np.dot(res,weights[1][0]);
res = np.maximum(res,0);
res = np.dot(res,weights[2][0]);
res = np.maximum(res,0);


y_final_prediction = grid.predict(res)

x = numpy.zeros(shape=(target_mat.shape[0], target_mat.shape[1]))
count = 0;
for i in range(target_mat.shape[0]):
  for j in range(target_mat.shape[1]):
    x[i][j] = y_final_prediction[count];
    count = count+1;

import spectral
predict_image = spectral.imshow(classes = x.astype(int),figsize =(5,5))
predict_imag = spectral.imshow(classes = target_mat.astype(int),figsize =(5,5))